{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment - 4\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jacobi Method**\n",
    "\n",
    ">  Initialize the iterative solution vector $x^{(0)}$ randomly, or with the zero vector,\n",
    "\n",
    ">  for k=0:maxIteration, update every element until convergece\n",
    "\n",
    ">> for i=1:n\n",
    "$$\n",
    "x^{(k+1)}_i  = \\frac{1}{a_{ii}} \\left(b_i -\\sum_{j\\ne i}a_{ij}x^{(k)}_j\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can modify this code to answer the following\n",
    "'''\n",
    "Jacobi's iteration method for solving the system of equations Ax=b.\n",
    "p0 is the initialization for the iteration.\n",
    "'''\n",
    "def jacobi(A, b, p0, tol, maxIter=100):\n",
    "    n=len(A)\n",
    "    p = p0\n",
    "\n",
    "    for k in range(maxIter):\n",
    "        p_old = p.copy() # In python assignment is not the same as copy\n",
    "        \n",
    "        # Update every component of iterant p\n",
    "        for i in range(n):\n",
    "            sumi = b[i];\n",
    "            for j in range(n):\n",
    "                if i==j: # Diagonal elements are not included in Jacobi\n",
    "                    continue;\n",
    "                sumi = sumi - A[i,j] * p_old[j]\n",
    "            p[i] = sumi/A[i,i]\n",
    "                \n",
    "        rel_error = np.linalg.norm(p-p_old)/n # Actually 'n' should be replace by norm of p\n",
    "        # print(\"Relative error in iteration\", k+1,\":\",rel_error)\n",
    "        if rel_error<tol:\n",
    "            print(\"TOLERANCE MET BEFORE MAX-ITERATION\")\n",
    "            break\n",
    "    return p;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example System\n",
    "A = np.array([[10, -1, 2, 0],\n",
    "              [-1, 11, -1, 3],\n",
    "              [2, -1, 10, -1],\n",
    "              [0, 3, -1, 8]],dtype=float)\n",
    "b = np.array([6, 25, -11, 15],dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative error in iteration 1 : 0.800426224590622\n",
      "Relative error in iteration 2 : 0.3139108544397979\n",
      "Relative error in iteration 3 : 0.12422637853721896\n",
      "Relative error in iteration 4 : 0.054771292541808646\n",
      "Relative error in iteration 5 : 0.022436330141173605\n",
      "Relative error in iteration 6 : 0.009818643275500276\n",
      "Relative error in iteration 7 : 0.004080819123032458\n",
      "Relative error in iteration 8 : 0.001771786788931381\n",
      "Relative error in iteration 9 : 0.0007431997674230598\n",
      "Relative error in iteration 10 : 0.00032079033890472324\n",
      "Relative error in iteration 11 : 0.00013535311156012586\n",
      "Relative error in iteration 12 : 5.8186093290970545e-05\n",
      "Relative error in iteration 13 : 2.4643257169446926e-05\n",
      "Relative error in iteration 14 : 1.0564758745559243e-05\n",
      "Relative error in iteration 15 : 4.485247231921513e-06\n",
      "Relative error in iteration 16 : 1.9193612844546157e-06\n",
      "Relative error in iteration 17 : 8.161302435950022e-07\n",
      "Relative error in iteration 18 : 3.4882490269579057e-07\n",
      "Relative error in iteration 19 : 1.4847311290054845e-07\n",
      "Relative error in iteration 20 : 6.34092262543758e-08\n",
      "TOLERANCE MET BEFORE MAX-ITERATION\n",
      "The solution is:  [ 1.00000003  1.99999996 -0.99999997  0.99999995]\n"
     ]
    }
   ],
   "source": [
    "## What will happen if the followign code runs\n",
    "#x = jacobi(A,b, np.array([0,0,0,0]),0.00001, 100)\n",
    "\n",
    "x = jacobi(A,b, np.array([0,0,0,0],dtype=float),0.0000001, 100)\n",
    "print(\"The solution is: \",x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1**: Modify the code for Jacobi Method for the following:\n",
    ">- (A) Implement the Gauss-Siedel Iteration in Python.Â  Solve the following system by using this method. Exact answer is (1,2,-1,1). Stopping criteria could be a relative $error < 0.00001$.\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "10 & -1  & 2  & 0  \\\\\n",
    "-1 & 11&-1 & 3 \\\\\n",
    "2 & -1  & 10  & -1 \\\\\n",
    "0 & 3 & -1 & 8  \n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "x_1\\\\x_2\\\\x_3\\\\x_4 \n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "6\\\\25\\\\-11\\\\15\n",
    "\\end{pmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "def GS(A, b, p0, tol, maxIter=100):\n",
    "    n=len(A)\n",
    "    p = p0\n",
    "\n",
    "    for k in range(maxIter):\n",
    "        p_old = p.copy() # In python assignment is not the same as copy\n",
    "        \n",
    "        # Update every component of iterant p\n",
    "        for i in range(n):\n",
    "            sumi = b[i];\n",
    "            for j in range(n):\n",
    "                if i==j: # Diagonal elements are not included in Jacobi\n",
    "                    continue;\n",
    "                sumi = sumi - A[i,j] * p[j]  \n",
    "            p[i] = sumi/A[i,i]\n",
    "            \n",
    "        rel_error = np.linalg.norm(p-p_old)/np.linalg.norm(p) # Actually 'n' should be replace by norm of p\n",
    "        # print(\"Relative error in iteration\", k+1,\":\",rel_error)\n",
    "        if rel_error<tol:\n",
    "            print(\"TOLERANCE MET BEFORE MAX-ITERATION\")\n",
    "            break\n",
    "    return p;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative error in iteration 1 : 1.0\n",
      "Relative error in iteration 2 : 0.19751435915787618\n",
      "Relative error in iteration 3 : 0.01690920825126704\n",
      "Relative error in iteration 4 : 0.0026865642906146927\n",
      "Relative error in iteration 5 : 0.0003304693868120267\n",
      "Relative error in iteration 6 : 3.4251410744752034e-05\n",
      "Relative error in iteration 7 : 3.1066378334949327e-06\n",
      "Relative error in iteration 8 : 2.471638585143502e-07\n",
      "Relative error in iteration 9 : 1.671876777260536e-08\n",
      "TOLERANCE MET BEFORE MAX-ITERATION\n",
      "The solution is [ 1.  2. -1.  1.]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[10, -1, 2, 0],\n",
    "              [-1, 11, -1, 3],\n",
    "              [2, -1, 10, -1],\n",
    "              [0, 3, -1, 8]],dtype=float)\n",
    "b = np.array([6, 25, -11, 15],dtype=float)\n",
    "\n",
    "x = GS(A,b, np.array([0,0,0,0],dtype=float),0.0000001, 100)\n",
    "print(f'The solution is {x}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- (B) Implement Successive Over-relaxation in Python and solve the above problem again with $\\omega=1.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "def SOR(A, b, p0, w, tol, maxIter=100):\n",
    "    n=len(A)\n",
    "    p = p0\n",
    "\n",
    "    for k in range(maxIter):\n",
    "        p_old = p.copy() # In python assignment is not the same as copy\n",
    "        \n",
    "        # Update every component of iterant p\n",
    "        for i in range(n):\n",
    "            sumi = b[i];\n",
    "            for j in range(n):\n",
    "                if i==j: # Diagonal elements are not included in Jacobi\n",
    "                    continue;\n",
    "                sumi = sumi - A[i,j] * p[j]\n",
    "            p[i] = (1-w)*p[i] + (w*sumi)/A[i,i]\n",
    "            \n",
    "        rel_error = np.linalg.norm(p-p_old)/np.linalg.norm(p) # Actually 'n' should be replace by norm of p\n",
    "        # print(\"Relative error in iteration\", k+1,\":\",rel_error)\n",
    "        if rel_error<tol:\n",
    "            print(\"TOLERANCE MET BEFORE MAX-ITERATION\")\n",
    "            break\n",
    "    return p;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative error in iteration 1 : 1.0\n",
      "Relative error in iteration 2 : 0.8796914550709912\n",
      "Relative error in iteration 3 : 0.5054941511227775\n",
      "Relative error in iteration 4 : 0.1983179143689192\n",
      "Relative error in iteration 5 : 0.11388527680015631\n",
      "Relative error in iteration 6 : 0.06391874068316053\n",
      "Relative error in iteration 7 : 0.033340331709794224\n",
      "Relative error in iteration 8 : 0.017247370975101345\n",
      "Relative error in iteration 9 : 0.00902546583402039\n",
      "Relative error in iteration 10 : 0.004515719665739897\n",
      "Relative error in iteration 11 : 0.002049591132830533\n",
      "Relative error in iteration 12 : 0.001020145593735792\n",
      "Relative error in iteration 13 : 0.0005976711834246259\n",
      "Relative error in iteration 14 : 0.0003203773851562741\n",
      "Relative error in iteration 15 : 0.00014934983829159452\n",
      "Relative error in iteration 16 : 7.396361092404079e-05\n",
      "Relative error in iteration 17 : 4.238019071719031e-05\n",
      "Relative error in iteration 18 : 2.282465109350173e-05\n",
      "Relative error in iteration 19 : 1.1241535499717385e-05\n",
      "Relative error in iteration 20 : 5.825857796592088e-06\n",
      "Relative error in iteration 21 : 3.1409285134061924e-06\n",
      "Relative error in iteration 22 : 1.5436992090726753e-06\n",
      "Relative error in iteration 23 : 7.298755978764908e-07\n",
      "Relative error in iteration 24 : 3.9783120701544474e-07\n",
      "Relative error in iteration 25 : 2.2240614434472037e-07\n",
      "Relative error in iteration 26 : 1.0896117550684893e-07\n",
      "Relative error in iteration 27 : 5.138341674794225e-08\n",
      "TOLERANCE MET BEFORE MAX-ITERATION\n",
      "The solution is [ 0.99999998  1.99999996 -0.99999997  0.99999999]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[10, -1, 2, 0],\n",
    "              [-1, 11, -1, 3],\n",
    "              [2, -1, 10, -1],\n",
    "              [0, 3, -1, 8]],dtype=float)\n",
    "b = np.array([6, 25, -11, 15],dtype=float)\n",
    "w = 1.5\n",
    "\n",
    "y = SOR(A,b, np.array([0,0,0,0],dtype=float), w,0.0000001, 100)\n",
    "print(f'The solution is {y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2** : Modify the code for gradient descent method to find the minimum for a function in two variables. Show the output for the following function by using your code. \n",
    "$$\n",
    "f(x_1, x_2) = x_1^2+x_2^2-2x_1+4x_2+8\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Iteration 1: 0.20000000\n",
      "\n",
      " Iteration 2: 0.36000000\n",
      "\n",
      " Iteration 3: 0.48800000\n",
      "\n",
      " Iteration 4: 0.59040000\n",
      "\n",
      " Iteration 5: 0.67232000\n",
      "\n",
      " Iteration 6: 0.73785600\n",
      "\n",
      " Iteration 7: 0.79028480\n",
      "\n",
      " Iteration 8: 0.83222784\n",
      "\n",
      " Iteration 9: 0.86578227\n",
      "\n",
      " Iteration 10: 0.89262582\n",
      "\n",
      " Iteration 11: 0.91410065\n",
      "\n",
      " Iteration 12: 0.93128052\n",
      "\n",
      " Iteration 13: 0.94502442\n",
      "\n",
      " Iteration 14: 0.95601953\n",
      "\n",
      " Iteration 15: 0.96481563\n",
      "\n",
      " Iteration 16: 0.97185250\n",
      "\n",
      " Iteration 17: 0.97748200\n",
      "\n",
      " Iteration 18: 0.98198560\n",
      "\n",
      " Iteration 19: 0.98558848\n",
      "\n",
      " Iteration 20: 0.98847078\n",
      "\n",
      " Iteration 21: 0.99077663\n",
      "\n",
      " Iteration 22: 0.99262130\n",
      "\n",
      " Iteration 23: 0.99409704\n",
      "\n",
      " Iteration 24: 0.99527763\n",
      "\n",
      " Iteration 25: 0.99622211\n",
      "\n",
      " Iteration 26: 0.99697769\n",
      "\n",
      " Iteration 27: 0.99758215\n",
      "\n",
      " Iteration 28: 0.99806572\n",
      "\n",
      " Iteration 29: 0.99845257\n",
      "\n",
      " Iteration 30: 0.99876206\n",
      "\n",
      " Iteration 31: 0.99900965\n",
      "\n",
      " Iteration 32: 0.99920772\n",
      "\n",
      " Iteration 33: 0.99936617\n",
      "\n",
      " Iteration 34: 0.99949294\n",
      "\n",
      " Iteration 35: 0.99959435\n",
      "\n",
      " Iteration 36: 0.99967548\n",
      "\n",
      " Iteration 37: 0.99974039\n",
      "\n",
      " Iteration 38: 0.99979231\n",
      "\n",
      " Iteration 39: 0.99983385\n",
      "\n",
      " Iteration 40: 0.99986708\n",
      "\n",
      " Iteration 41: 0.99989366\n",
      "\n",
      " Iteration 42: 0.99991493\n",
      "\n",
      " Iteration 43: 0.99993194\n",
      "\n",
      " Iteration 44: 0.99994555\n",
      "\n",
      " Iteration 45: 0.99995644\n",
      "\n",
      " Iteration 46: 0.99996516\n",
      "\n",
      " Iteration 47: 0.99997212\n",
      "\n",
      " Iteration 48: 0.99997770\n",
      "\n",
      " Iteration 49: 0.99998216\n",
      "\n",
      " Iteration 50: 0.99998573\n",
      "\n",
      " Iteration 51: 0.99998858\n",
      "\n",
      " Iteration 52: 0.99999087\n",
      "\n",
      " Iteration 53: 0.99999269\n",
      "\n",
      " Iteration 54: 0.99999415\n",
      "\n",
      " Iteration 55: 0.99999532\n",
      "\n",
      " Iteration 56: 0.99999626\n",
      "\n",
      " Iteration 57: 0.99999701\n",
      "\n",
      " Iteration 58: 0.99999761\n",
      "The minimum of the given function is f(0.9999976054757287, -1.9999952109514307) = 3.0000000000286686 \n"
     ]
    }
   ],
   "source": [
    "def derivative(f, x_value, y_value):\n",
    "    h=0.01\n",
    "    # Numerical differentialtion of f at x_value by central difference formula\n",
    "    dx = (f(x_value+h, y_value) - f(x_value-h, y_value)) /(2*h)\n",
    "    dy = (f(x_value, y_value+h) - f(x_value, y_value-h)) /(2*h)\n",
    "    return dx, dy\n",
    "\n",
    "def gradient_descent(f, x0=0.0, y0=0.0, delta=0.000001, max_iter=100, alpha=0.1):\n",
    "    x_current = x0\n",
    "    y_current = y0\n",
    "    for i in range(max_iter):\n",
    "        # Find the derivative or approximate derivative at x_current\n",
    "        df1, df2 = derivative(f, x_current, y_current)\n",
    "        # The gradient descent step\n",
    "        x_next = x_current - alpha*df1\n",
    "        y_next = y_current - alpha*df2\n",
    "        # Stop iterating once desired accuracy is achieved\n",
    "        if(np.abs(x_next - x_current) and np.abs(y_next - y_current) < delta):\n",
    "            break\n",
    "        x_current  = x_next\n",
    "        y_current = y_next\n",
    "        print(\"\\n Iteration {0:d}: {1:.8f}\".format(i+1,x_current))\n",
    "    return x_current, y_current, f(x_current, y_current)\n",
    "\n",
    "func = lambda x, y: x**2 + y**2 - 2*x + 4*y + 8\n",
    "\n",
    "x_min, y_min, min_value = gradient_descent(func)\n",
    "print(\"The minimum of the given function is f({}, {}) = {} \".format(x_min, y_min, min_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
